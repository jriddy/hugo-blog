<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>The POSIX Shell is Unix Jank | Josh Reed</title><meta name=keywords content><meta name=description content="The standard-ish Unix shell is a disjointed monstrosity riddled with incongruous features agglomerated from inconsistent design decisions made at various times for unknown reasons by a unknowable multitude of developers.
It is also one of the most important pieces of software in the world today.
Sure would be nice if it didn&rsquo;t suck.
Digital wizardry
Early in my Unix journey, I was in awe of the shell.  Watching my friend who had grown comfortable with the shell was like watching a master work with his tools.  The data yielded to his precise commands like putty in his hands.  The arcane symbols and abstruse output flew by, totally unintelligible to me, but clearly full of meaning for him, as he worked to configure some webserver on a Linux machine.  Was he a wizard?  No.  He was a hacker.  I wanted to be one too."><meta name=author content><link rel=canonical href=http://www.jriddy.com/posts/posix-shell-jank/><link crossorigin=anonymous href=/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css integrity="sha256-j+ECM6cGvIfy4Is8+XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as=style><link rel=icon href=http://www.jriddy.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://www.jriddy.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://www.jriddy.com/favicon-32x32.png><link rel=apple-touch-icon href=http://www.jriddy.com/apple-touch-icon.png><link rel=mask-icon href=http://www.jriddy.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://www.jriddy.com/posts/posix-shell-jank/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="http://www.jriddy.com/posts/posix-shell-jank/"><meta property="og:site_name" content="Josh Reed"><meta property="og:title" content="The POSIX Shell is Unix Jank"><meta property="og:description" content="The standard-ish Unix shell is a disjointed monstrosity riddled with incongruous features agglomerated from inconsistent design decisions made at various times for unknown reasons by a unknowable multitude of developers.
It is also one of the most important pieces of software in the world today.
Sure would be nice if it didn’t suck.
Digital wizardry Early in my Unix journey, I was in awe of the shell. Watching my friend who had grown comfortable with the shell was like watching a master work with his tools. The data yielded to his precise commands like putty in his hands. The arcane symbols and abstruse output flew by, totally unintelligible to me, but clearly full of meaning for him, as he worked to configure some webserver on a Linux machine. Was he a wizard? No. He was a hacker. I wanted to be one too."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-09-25T16:19:58-04:00"><meta property="article:modified_time" content="2025-09-25T16:19:58-04:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="The POSIX Shell is Unix Jank"><meta name=twitter:description content="The standard-ish Unix shell is a disjointed monstrosity riddled with incongruous features agglomerated from inconsistent design decisions made at various times for unknown reasons by a unknowable multitude of developers.
It is also one of the most important pieces of software in the world today.
Sure would be nice if it didn&rsquo;t suck.
Digital wizardry
Early in my Unix journey, I was in awe of the shell.  Watching my friend who had grown comfortable with the shell was like watching a master work with his tools.  The data yielded to his precise commands like putty in his hands.  The arcane symbols and abstruse output flew by, totally unintelligible to me, but clearly full of meaning for him, as he worked to configure some webserver on a Linux machine.  Was he a wizard?  No.  He was a hacker.  I wanted to be one too."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://www.jriddy.com/posts/"},{"@type":"ListItem","position":2,"name":"The POSIX Shell is Unix Jank","item":"http://www.jriddy.com/posts/posix-shell-jank/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"The POSIX Shell is Unix Jank","name":"The POSIX Shell is Unix Jank","description":"The standard-ish Unix shell is a disjointed monstrosity riddled with incongruous features agglomerated from inconsistent design decisions made at various times for unknown reasons by a unknowable multitude of developers.\nIt is also one of the most important pieces of software in the world today.\nSure would be nice if it didn\u0026rsquo;t suck.\nDigital wizardry Early in my Unix journey, I was in awe of the shell. Watching my friend who had grown comfortable with the shell was like watching a master work with his tools. The data yielded to his precise commands like putty in his hands. The arcane symbols and abstruse output flew by, totally unintelligible to me, but clearly full of meaning for him, as he worked to configure some webserver on a Linux machine. Was he a wizard? No. He was a hacker. I wanted to be one too.\n","keywords":[],"articleBody":"The standard-ish Unix shell is a disjointed monstrosity riddled with incongruous features agglomerated from inconsistent design decisions made at various times for unknown reasons by a unknowable multitude of developers.\nIt is also one of the most important pieces of software in the world today.\nSure would be nice if it didn’t suck.\nDigital wizardry Early in my Unix journey, I was in awe of the shell. Watching my friend who had grown comfortable with the shell was like watching a master work with his tools. The data yielded to his precise commands like putty in his hands. The arcane symbols and abstruse output flew by, totally unintelligible to me, but clearly full of meaning for him, as he worked to configure some webserver on a Linux machine. Was he a wizard? No. He was a hacker. I wanted to be one too.\nAwe is the right word for what I felt here. We use awesome quite casually these days, but to say we’re in awe is reserved for a more serious, almost spiritual experience. Up until then, I had only really dealt with windowed GUIs. GUIs were obviously more approachable, but they were limited in that you can only ever do actions the GUI developer had specifically programmed. These shell prompts seemed so abstract and unbounded by comparison. If I used a shell instead, I would not limited by the software. I could do whatever I want, provided I could craft the right command. Here was real power, right at my fingertips, if only I could read the symbols.\nIt sounds crazy to attribute this admiration to shell, right? It’s just goofy lines of text on the screen. But this is really a big part of what got me into computers. It’s why I installed Linux on my parents computer when I was 13 and made crash. It’s why I learned to program in high school. Digital alchemy was available to those who could learn how to make these things work.\nThis image isn’t totally unique to programmer-types. Even Hollywood loves to makes shell and code fly by on a hacker’s screen as a visual shorthand for their technical wizardry. There’s a reason why these depictions work. It’s alluring to think there’s secret knowledge available to us just beyond our reach: that if we could master the arcane incantations it requires, we could bend reality to our will. So the trope persists. Regular humans use GUIs. Real hackers use shell.\nAn indispensable tool of the trade This isn’t just a silly affectation. I genuinely use shell in my work more than almost any other tool. And I’m not just banging out one-liners into an interactive prompt, although I do plenty of that. No, I commit shell scripts to repositories. I write tests for shell scripts. I use shell scripts as fundamental elements of production workflows.\nAs a SiteReliabilityDevSecOpsPlatformInfra Engineer, a huge amount of my work involves bridging disparate domains and configuring big, complex pieces of software in such a way that they work together. Shell is the near-ideal tool for this. It’s ubiquitous. It’s approachable. It’s malleable. It’s the perfect glue language.\nPerhaps calling it glue is underselling it. We typically don’t think of glue as super important in construction projects—although you might be surprised how critical adhesives are for a variety of uses—nor do we think of glue as having much internal complexity. Shell ends up being more like custom couplings between various parts of a system: small pieces improvised to get a component wired up to another or to shuttle some critical pieces of data across a gap.\nYou could think of conventional software as the major components of a car: the engine could be a database, the transmission could be a backend server, and the tires could be frontend applications. As important as these bits are, if that’s all we got, we’re not going anywhere. We need linkages between these components to create a full powertrain. In a typical software deployment, this is going to be a combination of off-the-shelf open-source support tools and a ton of configuration files. And anywhere there’s a disconnect between what the components expect and the reality of their environment, there’s bound to be a little script to bridge that chasm.\nThe upshot is that shell, along with other glue technologies, becomes critical infrastructure quite easily. Because it’s so ubiquitous you can rely on it to fill gap you might find on a Unix machine. Well, I mean any gap between executable programs on that machine.\nYou see, shell is really just a domain-specific language for calling other programs. That may not sound like much, but it’s incredibly powerful. It’s this feature that makes it perfect for glue in a way other languages are not. Most of the things you type into a shell script are just going to treated as names of other programs or arguments passed to them. The rest is mostly capturing program output, composing programs together, and interpolating variables into program inputs. There’s some other interesting abilities but these are the big ones.1\nIt’s this limited but powerful set of abilities that makes it so effective in the glue role. Unlike languages like Lua, Python, or Ruby, which can also function in this space, there’s not much pressure to start making larger programs or components that themselves need to be glued together. In contrast, Lua, Python, and Ruby are languages that are designed to make it easy to express business or domain logic, often with the help of extensive libraries and third-party code. They are general-purpose languages in every sense of that term.\nBut being general-purpose is different from fit-for-purpose. Domain-specific languages exist for a reason. There’s no reason I couldn’t express configuration or vector graphics or web markup as Python code, but we seldom do that because there are better tools for these jobs. Hell, Python used to express package metadata in itself (setup.py) until it was conceded that there are a lot of problems using a executable script express these things and the ecosystem moved to a static config file. The new TOML format may have its problems, but it doesn’t allow or expect arbitrary code execution, and it ensures a declarative and relatively clean layout of relevant information that is easy to parse visually and doesn’t permit arbitrary code execution. By giving up certain features, we actually gain confidence and understanding.\nThe same is true of shell. It’s not convenient to express complex business logic in shell, so we delegate that to larger programs. We can use shell to calculate and pass arguments to these larger programs, or to compose programs together in useful ways. The limited feature set becomes a forcing function for modular, component-based design. Sure, you can end up with too much shell this way, and it can become hard to follow, but that difficulty itself is usually the code telling you its time to create a new component. This is analogous to discovering abstractions as opposed to creating them. We don’t create whole-cloth glue components until we have concrete use cases that show us how we need them.\nThis work pattern has made me a better programmer in general. Maybe that’s because my role is more of a compositor than many developers, but I think a lot of folks could benefit from this more pragmatic approach. It certainly helps avoid doing more work than necessary, and I will always contend that avoiding unnecessary work is a far more valuable skill as a developer than being able to crank out lines-of-code at a breakneck pace.\nCracks in the Mortar For all my effusive praise of the shell-first paradigm, I actually think the Bourne shell and its descendants kinda suck. I mean, they get the core paradigm right—basic string interpolation, output capture, and pipelines are insanely powerful tools—but they are also old and crufty, invented in a different era of computing, and they have failed to evolve to keep up with the time. I called shell a “domain-specific language for calling other programs”, and while that’s true, if you take a step back, you can see that it leaves a lot to be desired in that role.\nA DSL for calling programs should be able to gracefully handle the results of calling programs. I mean the successful results, and the failures. This is the most glaring problem with shell code. It should be able to handle errors in a sensible way, but 50+ years into using it and the best we’ve got is set -e, which still kinda sucks.\nLet me cut right to the chase: ignoring errors is a terrible default. It was a design mistake in 1979 when the Bourne shell was introduced—Lisp REPLs had existed for 15 years at that point and experimented with multiple ways to handle errors in an interactive context2—and it is a goddamn travesty that we still have to live with this inane behavior. I understand it’s for backward compatibility, but it feels like a behavior you could opt into for compatibility mode, rather than keeping it as the primary behavior of a shell.\nI’m probably not being fair to the language designers. This is, after all, how C works. But it’s widely viewed as one of the biggest problems with C. While programmers don’t always agree how errors should be handled, we seem to all agree these days that it should be hard to just ignore them. This consensus had mostly solidified by the time I sat down to code. I have been programming for 20 years and I don’t think I’ve every written a line of code with the assumption that the line directly above it might fail and then just execute my code anyways.\nThis doesn’t make sense even for human algorithms. If I’m explaining to you how to mow the lawn, I might say:\nStart the lawnmower. Push the lawnmower around the whole surface of the lawn. Turn off the lawnmower. What the lawnmower failed to start? Would you push it around the lawn anyways? No! You’d come get me and tell me there’s a problem and it won’t start. Imagine how dense you’d have to ignore failure at the first step. Typical human narratives and processes tend to assume that sequence implies causality. In this case, starting the lawnmower causes a condition that makes pushing the lawnmower useful. This implication is so strong in lists of instructions that we have to specifically call when steps are optional.\nIn shell, as far as I can tell, this behavior of ignoring errors seems to exist to support the interactive case, although I don’t have the history on it and I could be wrong. But whatever the reason, it’s still a bad design choice, at least in retrospect. Yet it persists.\n“But wait!” you interject. “All of this can be fixed with set -e.” Well, bless your adorable little heart, if only it were so simple. This errexit feature works by simply checking the exit code after a command runs, and exiting the shell process if it is non-zero. This would work, except that there are critical shell features that conflict with this principle in non-obvious ways. Pipelines run commands in parallel, meaning we have to interpret the semantics of multiple error codes. Outer statements can suppress the exit code of inner statement in command substitution scenarios. The if statement interprets error codes as a boolean, where 0 is true and non-zero is false, leading to swallowed errors. That means grep text /dev/null and grep text /nonexistent both are interpreted as false in a boolean context, even if the second is clearly a file-not-found error. And all of this subtle behavior can vary between shell flavors, versions, and which options are set. Don’t even get me started on the interaction between all these options and subshells.\nActually, subshells themselves are exemplary of the quirky and non-intuitive way shell languages can futz with your shiz. It seems simple enough that shell might fork() at times for various reasons, and there are certainly times you want this, e.g. explicit subshells like (cd foo-dir || exit; bar-cmd baz-arg; ...). But there are several constructs that do this without it being obvious, like pipelines and redirection. You’ll know what I mean if you’ve ever tried to read command output through a pipe. Or if you’ve tried to mutate variables in a function and have that stop working when you change the call site from a simple function call my_func to a command substitution result=$(my_func), which makes all your my_func changes happen in a separate process.\nThere are, of course, workarounds for most of this issues. But also the exact behavior of your shell varies depending on which shell flavor you’re running (sh, bash, dash, zsh, ksh, etc.), which version of that shell you’re using, and which options and modes are enabled (e.g., POSIX mode, lastpipe). I’m exhausted just explaining this nonsense. It’s ten times worse trying to write code and remember all this minutiae while also, you know, keeping your actual problem in mind.\nThat’s where this stuff adds up to detract from the usefulness of shell. It’s not impossible to work with once you understand the main quirks and gotchyas, but all that stuff takes up valualbe mindspace where your domain problem should be. The bizarre syntax doesn’t help either. Wasn’t shell about simply gluing together the odd bits of our other solutions and smoothing over those rough edges? I’m sorry, I can’t see whether those edges are smooth because my eyes are still bleeding from trying to visually parse ${#options[*]}, ${values[@]^^?}, ${!var####}, and :(){ :|:\u0026 };:.\nThere is, of course, an element to subjectivity in determining what is and isn’t hard to read. But Bourne Shell-derived languages combine a strange feature set with a difficult syntax in way that takes up far more cognitive real estate than a tool in its space should. And this awkward unapproachability discourages many a developer from embracing the utility of shell coding. We really need something that gets out of our way.\nSome of this gratuitous syntax can be avoided. Because of shell pipelines and the near-universal availability of some common tools, we can send our strings through other programs to do our text manipulation for us. There’s the ever-popular sed which is used mostly to perform replacements in files and streams, so it can be used for variables too. That’s neat, but sed is also its own whole-ass language with its own design quirks and inconsistencies between versions. Have you ever done shell argument pre-processing to pass a variable to sed to do text transformation you couldn’t figure out how to do in shell? It’s starting to feel like the cure is worse than the disease. And sed really isn’t that powerful, or at least its super terse syntax makes expressing more complicated things so cumbersome that its power is unavailable to mere mortals.\n“Don’t worry,” you tell me, “you can always use AWK!” Bruh, stop naming text-processing mini-languages. You’re scaring the hoes. Anyways, awk is another 1970s Bell Labs creation that has made its way onto virtually every base Unix install everywhere. It has its own quirks and version inconsistencies and strengths and weaknesses that you apparently need to know in order to read other people’s shell code because it’s been around so long and some people have gotten used to it that it’s now critical infrastructure. Fun times.\nIt’s super neat that shell can reach out to other tools when it lacks those abilities itself. And parsing complex text is certainly a more complicated task than one should rightly expect to see included in shell. But we shouldn’t need to parse arbitrary text formats. Back here in the future, programs consume and output structured data represented in a handful of well-known exchange formats. Like JSON. At some point in the 2000s, everybody agreed that you only need a handful of primitive data types, and two compound ones, and you can encode almost anything you want in a format that is a decent compromise between human readability and machine parser-friendliness.\nOh, but shell lacks these data types. It mostly has strings and arrays of strings. Even, arrays aren’t even supported in POSIX, and newer shell support for them varies greatly. This makes sense: this is 1970s technology we’re talking about here. It probably save a ton of time in the interpreter to skip all type checks. But in the modern age it just feels like an egregious lack, because it means we’ll never be able to deal with pre-structured data.\n“Hey, you can use jq for dealing with JSON!” you interject, like a smart-ass. What did I say about naming more mini-languages? STOP IT! Yes, this does work, but it has all the problems of sed and awk: namely, that I have to learn a whole ’nother language and all its quirks. Sadly, unlike sed and awk, which predate the fall of disco, jq and its brother-from-another-mother curl are rarely installed in “base” OS builds. You have to figure out how to install them before you use them. This can be solved fairly easily by containers in some cases, but not always when you need portability. This is a lot of junk to remember.\nAll of this might have made sense at some past time, when the idea of querying a server over HTTP and extracting information from the response was some rare and niche use case. But it is 2025 and everything is an API now. It seems like our glue code should be able to keep up with that.\nShell: the good parts? Let’s check the score here. I called shell a “DSL for calling other programs.” What makes it good for that role?\nCalling other programs is syntactically obvious and natural. Composing programs together is extremely easy. It is challenging to “overdo it” in shell. What makes it terrible for that role?\nIt is extremely challenging to handle errors properly and consistently. Loads of quirky syntax and surprising behaviors crowd out domain logic. It lacks a way to represent or process JSON data types, which are the lingua franca of modern computing. It really seems like it should be simple to solve these problems. But a strong desire for backwards-compatibility in the shell world has made it all but impossible. There are fundamental design problems with how Bourne Shell-derived languages work. The base semantics of the language have no way to distinguish between results and output streams, other than a single byte of data that we call the exit code, which is itself overloaded with both error and boolean meanings. This is not a problem you can patch.\nI won’t deny that working with zsh or modern bash is vastly superior to using a classic shell. Features like errexit and lastpipe do generally reduce the pain of common shell behaviors, even if they can also lead to some surprising issues. And while I think it’s safe to say that these shells have made improvements on POSIX shell, I wonder if some of these improvements just make it easier to start tackling harder problems with a language that is ill-suited for it. Do I really want associative arrays if I can’t easily tell if a key is present or not? Were coprocs really the missing feature we needed to make concurrent programming tractable in shell?\nWhat we actually need are some things “regular” programming languages have had for decades: return values and exceptions. These features essentially solve the error-handling problem outright, and provide the building blocks (structured data types) that you need to solve the JSON problem. But, since these semantics would utterly break compatibility with POSIX shell, they haven’t been pushed in any mainstream Unix shell implementation I’m aware of. Outside the mainstream, folks have been trying to re-integrate features like this into shell since at least as early as 1993.\nBut for the rest of us, all this utility gets sacrificed on the altar of POSIX compatibility. Which… I mean, do we really even need to be POSIX compatible? Why do we care so much? Hell, I’d argue a lot of shell code writers don’t even realize when they are using Bashisms (or Zshisms for that matter). The times when we actually need to write very compatible shell code are quite limited, and you can use ShellCheck to check for many of the most common issues. Going further, you could look for a minimal POSIX-compatible shell to develop against when you need this. That combined with, you know, actual testing will cover you for compatibility.\nAlternative Shells I don’t want to pretend compatibility isn’t important. There are clear times when various Unix-ecosystem constructs expect POSIX-compatibility. But it is a limited set of things and is probably disjoint with 95% of your work unless you’re a distro package maintainer. You are free to use non-compatible shell for most of your life, and drop into a simple Bourne-shell thingy in the rare event that you need it.\nLet’s elaborate: you have control on your personal machines. You almost certainly control what shell runs in your development environment. You might be able to influence what runs on your team’s servers. These are all chances to try out new tools. But what tool to try?\nThis gets a bit tricky because, there’s a ton of options, and no clear community consensus, as is always the case when veering away from mainstream technology; if there was consensus we’d see a new branch in the mainstream, not an “alternative shell”. But there are a few generally good options.\nI personally use Fish as my daily driver, even though it only fixes one of my three main shell grips (the syntax one). But it comes with such a great out-of-the box interactive experience, that I can forgive it for not solving the others. I don’t need perfect error handling at the command line as often, since there’s a human in the loop. But I do love how it gets rid of POSIX shell eye-bleed in favor of a simple syntax and useful builtins. A lot of the ${var[@]##%} gobbledygook gets replaced with the string and path commands. Completion works like a charm, with little gray suggestions quietly extending beyond your cursor, gingerly offering themselves to you as you type, without getting pushy and hyperactive. Quoting behavior becomes a non issue, and variables have the values you expect, with no subshells and clear variable scopes.\nThat said, I still think fish is a pretty lousy scripting language, because it doesn’t solve the error/output problem. This is a big deal, and it’s why I’ve never bothered trying to fight with my team to install fish on servers or even use it in our repositories. But if you’re used to POSIX-descendant shells, it’s a great demonstration that it isn’t that hard to ditch all that historical baggage. Fish easy to get used to, and with the compatibility layer bass installed, you can consume bash scripts with ease, so you don’t get locked out of the shell-script ecosystem. It will give you a taste of what a better experience is like, with sensible defaults out-of-the box, without having to install an enormous framework or trying to sell you cringe T-shirts. Anecdotally, it’s also much faster than most bash or zsh-based plugin things I’ve tried, probably because most of the salient features are implemented in native code.\nWindows users would be remiss if I didn’t mention PowerShell, which is definitely not POSIX compatible and was never intended to be. I stopped working with Windows before I ever really learned it, so I’m not sure what the fuss is about, but it does seem to have structured data and is oriented around pipelines. And what do you know, it’s available on MacOS and Linux too! But it requires the (very large) Common Language Runtime VM and God-knows-what-else .NET gunk to run. So I’m going to pass on PowerShell for Unix. But if I ever end up in a project working with Windows again, I think it would be worth investing time to learn it instead of trying to hack it out with Unix shells on WSL.\nIn that vein, if you’re interested in the structured data pipelines emphasis, Nushell has you covered. Drawing on the design of PowerShell, Nushell aims to be cross-platform by default, and generally seems to be a bit tidier and more parsimonious than the shell that inspired it. It focuses on tabular, structured data, and DSLs for manipulating that. To this end, it reimplements a lot of typical Unix-style programs directly in the shell, to make them more aware of this data format. This does give me a bit of pause though. I’ve become skeptical of tools that become so convinced of the power of a particular worldview that they start contorting everything around them to fit that model. In a shell, if this made interacting with regular programs feel second-class, then it starts to move away from that “DSL for calling programs” sweet spot, and more into a “systems data processing language.” But I haven’t really tried it yet, so I can’t say if this is a valid criticism or just armchair architecture critique. Overall, with some neat ideas and a lot of polish put on it, Nushell definitely looks worth trying.\nAnother candidate for a replacement shell is Elvish. In some ways it seems similar to Nushell, but with less emphasis on the table presentation layer and more emphasis on being like a functional dynamic programming language. It really aims to feel like a big boy language, except with sigils and barewords-as-strings. At first glance, I’m getting “readable Perl” or “restrained Ruby” vibes, which I mean as compliments. Both of those languages arose out of the frustrations with handling more complex tasks in shell scripts. It also seems to avoid re-implementing common commands like Nushell, which makes me suspect it will feel a bit more natural interacting with tools you find in the wild. My only worry is that all this PL-focus—there’s mentions of work on package managers and type systems and macros!—will detract from the simple, raw domain logic you want in shell scripts. Advanced features like this make it much easier to build a big goopy mess. A big ball of mud is still a big ball of mud even if it’s really elegant mud.\nThe last alternative shell I’ll discuss is the Oils Project, which aims to provide an “upgrade path from Bash to a better language and runtime.” It does this by providing a Bash-compatible mode osh and then allowing you to layer on options until you get to ysh, a target language that ticks all the boxes I have, without even sacrificing compatibility. Seriously. It has exception-based error handling, actual return values, structured data, native JSON capabilities, and a Bash-compatible mode. Granted, the way it achieves this is by essentially having two language modes embedded into one: command mode, which is more like classic shell, and expression mode, which is more like Python on JavaScript. This does make it a bit more complex, and one of my big criticisms of Oil has got to be the syntax, which I’d suggest looks quite busy.\nIt’s also sorely lacking in polish, and I’m not sure it will ever be “finished” in any meaningful sense. As of today, there is no cute and easy installer; you have to build it from source to prove that you are worthy.3 The interactive experience is somewhat humdrum. The docs are incomplete. For a project that has being going on for 8-9 years that seems suspect. There are still important design decisions being worked out in the open. But at the same time, it’s almost refreshing seeing that someone is willing to be so deliberate when designing a language. And you can follow all of that design thinking in the Oils blog which goes back for years. So it’s worth reading up on the thought process that went into this, even if you don’t end up using it.\nFor me, Oils is simultaneously the most promising and most frustrating option. It legitimately aims to provide a path for us to “get off the Bell Labs timeline”, but I don’t know where this path leads. And I’m not sure the Oils folks know either! That could be exciting, but I feel like I need more re-assurance that a project will start to stabilize before I start leaning on it for load-bearing elements of my work.\nFinal Thoughts This may seem like a long, long post for such a lukewarm take—I am certainly neither the first nor the last person to claim the Bourne/POSIX shell sucks—but it’s a damn travesty that we are stuck here. The utility and power of the shell was what drew me into computing. It’s still one of the main selling points of Unix, sitting right at the core of the Unix philosophy: it is (generally) better to have many simple tools and a rich way to compose them than to have few complex tools that can’t work together. This notion is held back by weaknesses in the composition language.\nI’d go so far as to argue that the creation of many modern overly-complex god-programs is in some way attributable to the weaknesses of shell. Do you like to hate on systemd? I sure do! Well, it replaced a bunch of shitty, hard-to-maintain shell scripts for the folks who do nuts-and-bolts Linux distro work. Who knows? Maybe better shell could have prevented it. Are you tired of editing YAML for a living? A lot of that YAML is replacing things that could be expressed in shell, except shell can’t express structured data well so we have to embed shell inside of config files. Oops, I typed ${var} when I meant {{.var}}. Or was it ${{var}}? How silly of me to confuse one of the 5 templating languages I work with for another!\nWe are seriously still living in the past in so many ways because of this nonsense. And unlike some other ancient Unix jank like signals, we could mostly get rid of this! We generally get to pick the programs we write code in. There are some exceptions-login shells need to be able to process /etc/profile, and some tools like Vi or GDB expect $SHELL to reference a POSIX shell—but for the most part you can write shell scripting in whatever you want if you add a #!/she/bang, so what’s stopping us?\nTry one of these alternative shells. Seriously! Give it a go. If you’re not a big shell user,then maybe having a shell language with decent semantics will open your eyes to a new way of working. If you use shell all the time, it might be hard to break from usual habits, but you may end up liking it! If none of the alternatives I listed are appealing to you, take a look at the Oils wiki’s list of alternative shells and find something you like.\nTo move on from the Bell Labs timeline, we need to gain a critical mass of developers that regularly and confidently use non-POSIX shells. One of the better arguments for sticking with these old-timey shells is that they are well-worn and battle-tested. They have their faults but we know where they are. The only way to counter that is to start testing an alternative in new battles! Do this locally and privately at first.\nDon’t start jamming it into shared load-bearing infrastructure at work without talking to your team. No one likes being surprised with shiny new tech they don’t know without being consulted. This kinda thing leaves a bad taste in people’s mouths. It is perfectly reasonable to be skeptical of new technology, and perfectly understandable to be resentful when it is shoved down your throats. I don’t think any developers I know love POSIX shell, but many reasonable and intelligent folks think it’s the best choice given all the trade-offs. So I’m not going to fight to install a neoshell on our servers until I fully understand the implications of what that means.\nThat said, if you find yourself liking one of these, show it off to your team! Feature it during demo day, either live, or by scripting up some actions that you want to show off. Use it to solve problems you found difficult. Talk about it. Write about it. Emit microblog status updates about it. Show the world that there are alternatives. As I said before, I don’t think people love POSIX shell, I just think they are just resigned to the sludge, convinced that it is the least bad option for the task. Can we show them some good options?\nWe don’t all have to program in C anymore. Maybe one day we won’t all have to script in sh.\nI’m aware that shell is Turing complete and thus technically capable of writing any program. Thanks for reminding me, nerd. But I’m talking more about what shell’s design encourages and makes easy than what is technically possible. ↩︎\nI could probably levy this criticism at almost every language. There have been more features pioneered in Lisp than you can probably imagine, and there’s still some great ones that have yet to go mainstream. Did you know you can make exception handling code that prompts the user to choose options to fix the error condition? ↩︎\nIt’s not complicated and it builds fast, but this will be a hurdle to adoption for a lot of folks who’d rather just copy curl -sSf https://oils.pub/get-oils | sh into a terminal and press enter. ↩︎\n","wordCount":"5603","inLanguage":"en","datePublished":"2025-09-25T16:19:58-04:00","dateModified":"2025-09-25T16:19:58-04:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.jriddy.com/posts/posix-shell-jank/"},"publisher":{"@type":"Organization","name":"Josh Reed","logo":{"@type":"ImageObject","url":"http://www.jriddy.com/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://www.jriddy.com/ accesskey=h title="Josh Reed (Alt + H)">Josh Reed</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">The POSIX Shell is Unix Jank</h1><div class=post-meta><span title='2025-09-25 16:19:58 -0400 -0400'>September 25, 2025</span></div></header><div class=post-content><p>The standard-ish Unix shell is a disjointed monstrosity riddled with incongruous features agglomerated from inconsistent design decisions made at various times for unknown reasons by a unknowable multitude of developers.</p><p>It is also one of the most important pieces of software in the world today.</p><p>Sure would be nice if it didn&rsquo;t suck.</p><h2 id=digital-wizardry>Digital wizardry<a hidden class=anchor aria-hidden=true href=#digital-wizardry>#</a></h2><p>Early in my Unix journey, I was in <em>awe</em> of the shell. Watching my friend who had grown comfortable with the shell was like watching a master work with his tools. The data yielded to his precise commands like putty in his hands. The arcane symbols and abstruse output flew by, totally unintelligible to me, but clearly full of meaning for him, as he worked to configure some webserver on a Linux machine. Was he a wizard? No. He was a <em>hacker</em>. I wanted to be one too.</p><p><em>Awe</em> is the right word for what I felt here. We use <em>awesome</em> quite casually these days, but to say we&rsquo;re <em>in awe</em> is reserved for a more serious, almost spiritual experience. Up until then, I had only really dealt with windowed GUIs. GUIs were obviously more approachable, but they were limited in that you can only ever do actions the GUI developer had specifically programmed. These shell prompts seemed so abstract and unbounded by comparison. If I used a shell instead, I would not limited by the software. I could do <em>whatever I want</em>, provided I could craft the right command. Here was real power, right at my fingertips, if only I could read the symbols.</p><p>It sounds crazy to attribute this admiration to shell, right? It&rsquo;s just goofy lines of text on the screen. But this is really a big part of what got me into computers. It&rsquo;s why I installed Linux on my parents computer when I was 13 and made crash. It&rsquo;s why I learned to program in high school. Digital alchemy was available to those who could learn how to make these things work.</p><p>This image isn&rsquo;t totally unique to programmer-types. Even Hollywood loves to makes shell and code fly by on a hacker&rsquo;s screen as a visual shorthand for their technical wizardry. There&rsquo;s a reason why these depictions work. It&rsquo;s alluring to think there&rsquo;s secret knowledge available to us just beyond our reach: that if we could master the arcane incantations it requires, we could bend reality to our will. So the trope persists. Regular humans use GUIs. Real hackers use shell.</p><h2 id=an-indispensable-tool-of-the-trade>An indispensable tool of the trade<a hidden class=anchor aria-hidden=true href=#an-indispensable-tool-of-the-trade>#</a></h2><p>This isn&rsquo;t just a silly affectation. I genuinely use shell in my work more than almost any other tool. And I&rsquo;m not just banging out one-liners into an interactive prompt, although I do plenty of that. No, I commit shell scripts to repositories. I write tests for shell scripts. I use shell scripts as fundamental elements of production workflows.</p><p>As a SiteReliabilityDevSecOpsPlatformInfra Engineer, a huge amount of my work involves bridging disparate domains and configuring big, complex pieces of software in such a way that they work together. Shell is the near-ideal tool for this. It&rsquo;s ubiquitous. It&rsquo;s approachable. It&rsquo;s malleable. It&rsquo;s the perfect <em>glue</em> language.</p><p>Perhaps calling it <em>glue</em> is underselling it. We typically don&rsquo;t think of glue as super important in construction projects—although you might be surprised how critical adhesives are for a variety of uses—nor do we think of glue as having much internal complexity. Shell ends up being more like <em>custom couplings</em> between various parts of a system: small pieces improvised to get a component wired up to another or to shuttle some critical pieces of data across a gap.</p><p>You could think of conventional software as the major components of a car: the engine could be a database, the transmission could be a backend server, and the tires could be frontend applications. As important as these bits are, if that&rsquo;s all we got, we&rsquo;re not going <em>anywhere</em>. We need <em>linkages</em> between these components to create a full powertrain. In a typical software deployment, this is going to be a combination of off-the-shelf open-source support tools and a ton of configuration files. And anywhere there&rsquo;s a disconnect between what the components expect and the reality of their environment, there&rsquo;s bound to be a little script to bridge that chasm.</p><p>The upshot is that shell, along with other glue technologies, becomes <em>critical infrastructure</em> quite easily. Because it&rsquo;s so ubiquitous you can rely on it to fill gap you might find on a Unix machine. Well, I mean any gap between <em>executable programs</em> on that machine.</p><p>You see, shell is really just a domain-specific language for <em>calling other programs</em>. That may not sound like much, but it&rsquo;s incredibly powerful. It&rsquo;s this feature that makes it perfect for glue in a way other languages are not. Most of the things you type into a shell script are just going to treated as names of other programs or arguments passed to them. The rest is mostly capturing program output, composing programs together, and interpolating variables into program inputs. There&rsquo;s some other interesting abilities but these are the big ones.<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></p><p>It&rsquo;s this limited but powerful set of abilities that makes it so effective in the glue role. Unlike languages like Lua, Python, or Ruby, which can also function in this space, there&rsquo;s not much pressure to start making larger programs or components that themselves need to be glued together. In contrast, Lua, Python, and Ruby are languages that are designed to make it easy to express <em>business</em> or <em>domain logic</em>, often with the help of extensive libraries and third-party code. They are general-purpose languages in every sense of that term.</p><p>But being <em>general</em>-purpose is different from <em>fit</em>-for-purpose. Domain-specific languages exist for a reason. There&rsquo;s no reason I couldn&rsquo;t express configuration or vector graphics or web markup as Python code, but we seldom do that because there are better tools for these jobs. Hell, Python used to express package metadata in itself (<code>setup.py</code>) until it was conceded that there are a lot of problems using a executable script express these things and the ecosystem moved to a <a href=https://peps.python.org/pep-0518/>static config file</a>. The new TOML format may have its problems, but it doesn&rsquo;t allow or expect arbitrary code execution, and it ensures a declarative and relatively clean layout of relevant information that is easy to parse visually and doesn&rsquo;t permit arbitrary code execution. By giving up certain features, we actually gain confidence and understanding.</p><p>The same is true of shell. It&rsquo;s not convenient to express complex business logic in shell, so we delegate that to larger programs. We can use shell to calculate and pass arguments to these larger programs, or to compose programs together in useful ways. The limited feature set becomes a forcing function for modular, component-based design. Sure, you can end up with <em>too much shell</em> this way, and it can become hard to follow, but that difficulty itself is usually the code telling you its time to create a new component. This is analogous to <a href=https://lmerza.com/2024/04/16/abstractions-are-discovered-not-created/>discovering abstractions</a> as <a href=https://100go.co/5-interface-pollution/#interface-pollution_1>opposed to creating them</a>. We don&rsquo;t create whole-cloth glue <em>components</em> until we have concrete use cases that show us how we need them.</p><p>This work pattern has made me a better programmer in general. Maybe that&rsquo;s because my role is more of a <em>compositor</em> than many developers, but I think a lot of folks could benefit from this more pragmatic approach. It certainly helps avoid doing more work than necessary, and I will always contend that avoiding unnecessary work is a far more valuable skill as a developer than being able to crank out lines-of-code at a breakneck pace.</p><h2 id=cracks-in-the-mortar>Cracks in the Mortar<a hidden class=anchor aria-hidden=true href=#cracks-in-the-mortar>#</a></h2><p>For all my effusive praise of the shell-first paradigm, I actually think the Bourne shell and its descendants kinda suck. I mean, they get the core paradigm right—basic string interpolation, output capture, and pipelines are insanely powerful tools—but they are also old and crufty, invented in a different era of computing, and they have failed to evolve to keep up with the time. I called shell a &ldquo;domain-specific language for calling other programs&rdquo;, and while that&rsquo;s true, if you take a step back, you can see that it leaves a lot to be desired in that role.</p><p>A DSL for calling programs should be able to gracefully handle <em>the results</em> of calling programs. I mean the successful results, <em>and the failures</em>. This is the most glaring problem with shell code. It should be able to handle errors in a sensible way, but 50+ years into using it and the best we&rsquo;ve got is <code>set -e</code>, which still kinda sucks.</p><p>Let me cut right to the chase: <em>ignoring errors is a <strong>terrible</strong> default</em>. It was a design mistake in 1979 when the Bourne shell was introduced—Lisp REPLs had existed for <em>15 years</em> at that point and experimented with multiple ways to handle errors in an interactive context<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>—and it is a goddamn <em>travesty</em> that we still have to live with this inane behavior. I understand it&rsquo;s for backward compatibility, but it feels like a behavior you could opt <em>into</em> for compatibility mode, rather than keeping it as the primary behavior of a shell.</p><p>I&rsquo;m probably not being fair to the language designers. This is, after all, how C works. But it&rsquo;s widely viewed as one of the biggest problems with C. While programmers don&rsquo;t always agree <em>how</em> errors should be handled, we seem to all agree these days that it should be hard to just <em>ignore</em> them. This consensus had mostly solidified by the time I sat down to code. I have been programming for 20 years and I don&rsquo;t think I&rsquo;ve every written a line of code with the assumption that the line directly above it might fail and then just execute my code anyways.</p><p>This doesn&rsquo;t make sense even for <em>human</em> algorithms. If I&rsquo;m explaining to you how to mow the lawn, I might say:</p><ol><li>Start the lawnmower.</li><li>Push the lawnmower around the whole surface of the lawn.</li><li>Turn off the lawnmower.</li></ol><p>What the lawnmower failed to start? Would you push it around the lawn anyways? No! You&rsquo;d come get me and tell me there&rsquo;s a problem and it won&rsquo;t start. Imagine how dense you&rsquo;d have to ignore failure at the first step. Typical human narratives and processes tend to assume that sequence implies causality. In this case, starting the lawnmower causes a condition that makes pushing the lawnmower useful. This implication is so strong in lists of instructions that we have to specifically call when steps are <em>optional</em>.</p><p>In shell, as far as I can tell, this behavior of ignoring errors seems to exist to support the interactive case, although I don&rsquo;t have the history on it and I could be wrong. But whatever the reason, it&rsquo;s still a bad design choice, at least in retrospect. Yet it persists.</p><p>&ldquo;But wait!&rdquo; you interject. &ldquo;All of this can be fixed with <code>set -e</code>.&rdquo; Well, bless your adorable little heart, <a href=https://mywiki.wooledge.org/BashFAQ/105>if only it were so simple</a>. This <code>errexit</code> feature works by simply checking the exit code after a command runs, and exiting the shell process if it is non-zero. This would work, except that there are critical shell features that <a href=https://oils.pub/release/latest/doc/error-handling.html#fundamental-problems>conflict with this principle in non-obvious ways</a>. Pipelines run commands in parallel, meaning we have to interpret the semantics of <em>multiple</em> error codes. Outer statements can suppress the exit code of inner statement in command substitution scenarios. The <code>if</code> statement interprets error codes as a boolean, where 0 is true and non-zero is false, leading to swallowed errors. That means <code>grep text /dev/null</code> and <code>grep text /nonexistent</code> both are interpreted as <code>false</code> in a boolean context, even if the second is clearly a file-not-found error. And all of this subtle behavior can vary between shell flavors, versions, and which options are set. Don&rsquo;t even get me started on the interaction between all these options and <em>subshells</em>.</p><p>Actually, subshells themselves are exemplary of the quirky and non-intuitive way shell languages can futz with your shiz. It seems simple enough that shell might <code>fork()</code> at times for various reasons, and there are certainly times you want this, e.g. explicit subshells like <code>(cd foo-dir || exit; bar-cmd baz-arg; ...)</code>. But there are several constructs that do this without it being obvious, like pipelines and redirection. You&rsquo;ll know what I mean if you&rsquo;ve ever tried to <code>read</code> command output through a pipe. Or if you&rsquo;ve tried to mutate variables in a function and have that stop working when you change the call site from a simple function call <code>my_func</code> to a command
substitution <code>result=$(my_func)</code>, which makes all your <code>my_func</code> changes happen <em>in a separate process</em>.</p><p>There are, of course, <a href=https://mywiki.wooledge.org/BashFAQ/024>workarounds</a> for most of this issues. But also the exact behavior of your shell varies depending on which shell flavor you&rsquo;re running (<code>sh</code>, <code>bash</code>, <code>dash</code>, <code>zsh</code>, <code>ksh</code>, etc.), which <em>version</em> of that shell you&rsquo;re using, and which <em>options</em> and <em>modes</em> are enabled (e.g., POSIX mode, <code>lastpipe</code>). I&rsquo;m exhausted just explaining this nonsense. It&rsquo;s ten times worse trying to write code and remember all this minutiae while also, you know, keeping your actual problem in mind.</p><p>That&rsquo;s where this stuff adds up to detract from the usefulness of shell. It&rsquo;s not impossible to work with once you understand the main quirks and gotchyas, but all that stuff takes up valualbe mindspace where your domain problem should be. The bizarre syntax doesn&rsquo;t help either. Wasn&rsquo;t shell about simply gluing together the odd bits of our other solutions and smoothing over those rough edges? I&rsquo;m sorry, I can&rsquo;t see whether those edges are smooth because my eyes are still bleeding from trying to visually parse <code>${#options[*]}</code>, <code>${values[@]^^?}</code>, <code>${!var####}</code>, and <code>:(){ :|:& };:</code>.</p><p>There is, of course, an element to subjectivity in determining what is and isn&rsquo;t hard to read. But Bourne Shell-derived languages combine a strange feature set with a difficult syntax in way
that takes up far more cognitive real estate than a tool in its space should. And this awkward unapproachability discourages many a developer from embracing the utility of shell coding. We really need something that gets <em>out of our way</em>.</p><p>Some of this gratuitous syntax can be avoided. Because of shell pipelines and the near-universal availability of some common tools, we can send our strings through <em>other programs</em> to do our text manipulation for us. There&rsquo;s the ever-popular <code>sed</code> which is used mostly to perform replacements in files and streams, so it can be used for variables too. That&rsquo;s neat, but <code>sed</code> is also <em>its own whole-ass language</em> with its own design quirks and inconsistencies between versions. Have you ever done shell argument pre-processing to pass a variable to <code>sed</code> to do text transformation you couldn&rsquo;t figure out how to do in shell? It&rsquo;s starting to feel like the cure is worse than the disease. And <code>sed</code> really isn&rsquo;t that powerful, or at least its super terse syntax makes expressing more complicated things so cumbersome that its power is unavailable to mere mortals.</p><p>&ldquo;Don&rsquo;t worry,&rdquo; you tell me, &ldquo;you can always use AWK!&rdquo; Bruh, stop naming text-processing mini-languages. You&rsquo;re scaring the hoes. Anyways, <code>awk</code> is another 1970s Bell Labs creation that has made its way onto virtually every base Unix install everywhere. It has its own quirks and version inconsistencies and strengths and weaknesses that you apparently need to know in order to read other people&rsquo;s shell code because it&rsquo;s been around so long and some people have gotten used to it that it&rsquo;s now <em>critical infrastructure</em>. Fun times.</p><p>It&rsquo;s super neat that shell can reach out to other tools when it lacks those abilities itself. And parsing complex text is certainly a more complicated task than one should rightly expect to see included in shell. But we shouldn&rsquo;t need to parse arbitrary text formats. Back here in the future, programs consume and output <em>structured data</em> represented in a handful of well-known exchange formats. Like JSON. At some point in the 2000s, everybody agreed that you only need a handful of primitive data types, and two compound ones, and you can encode almost anything you want in a format that is a decent compromise between human readability and machine parser-friendliness.</p><p>Oh, but shell <em>lacks</em> these data types. It mostly has strings and arrays of strings. Even, arrays aren&rsquo;t even supported in POSIX, and newer shell support for them varies greatly. This makes sense: this <em>is</em> 1970s technology we&rsquo;re talking about here. It probably save a ton of time in the interpreter to skip all type checks. But in the modern age it just feels like an egregious lack, because it means we&rsquo;ll never be able to deal with pre-structured data.</p><p>&ldquo;Hey, you can use <code>jq</code> for dealing with JSON!&rdquo; you interject, like a smart-ass. What did I say about naming more mini-languages? STOP IT! Yes, this does work, but it has all the problems of <code>sed</code> and <code>awk</code>: namely, that I have to learn a whole &rsquo;nother language and all its quirks. Sadly, unlike <code>sed</code> and <code>awk</code>, which predate the fall of disco, <code>jq</code> and its brother-from-another-mother <code>curl</code> are rarely installed in &ldquo;base&rdquo; OS builds. You have to figure out how to install them before you use them. This can be solved fairly easily by containers in <em>some</em> cases, but not always when you need portability. This is a lot of junk to remember.</p><p>All of this might have made sense at some past time, when the idea of querying a server over HTTP and extracting information from the response was some rare and niche use case. But it is 2025 and <em>everything is an API now</em>. It seems like our glue code should be able to keep up with that.</p><h2 id=shell-the-good-parts>Shell: the good parts?<a hidden class=anchor aria-hidden=true href=#shell-the-good-parts>#</a></h2><p>Let&rsquo;s check the score here. I called shell a &ldquo;DSL for calling other programs.&rdquo; What makes it good for that role?</p><ol><li>Calling other programs is syntactically obvious and natural.</li><li>Composing programs together is extremely easy.</li><li>It is challenging to &ldquo;overdo it&rdquo; in shell.</li></ol><p>What makes it <em>terrible</em> for that role?</p><ol><li>It is extremely challenging to handle errors properly and consistently.</li><li>Loads of quirky syntax and surprising behaviors crowd out domain logic.</li><li>It lacks a way to represent or process JSON data types, which are the lingua franca of modern computing.</li></ol><p>It really seems like it should be simple to solve these problems. But a strong desire for backwards-compatibility in the shell world has made it all but impossible. There are fundamental design problems with how Bourne Shell-derived languages work. The base semantics of the language have no way to distinguish between results and output streams, other than a <em>single byte of data</em> that we call the exit code, which is itself overloaded with both error and boolean meanings. This is not a problem you can patch.</p><p>I won&rsquo;t deny that working with <code>zsh</code> or modern <code>bash</code> is vastly superior to using a classic shell. Features like <code>errexit</code> and <code>lastpipe</code> do generally reduce the pain of common shell behaviors, even if they can also lead to some surprising issues. And while I think it&rsquo;s safe to say that these shells have made <em>improvements</em> on POSIX shell, I wonder if some of these improvements just make it easier to start tackling harder problems with a language that is ill-suited for it. Do I really <em>want</em> associative arrays if I can&rsquo;t easily tell if a key is present or not? Were <em>coprocs</em> really the missing feature we needed to make concurrent programming tractable in <em>shell</em>?</p><p>What we actually need are some things &ldquo;regular&rdquo; programming languages have had for decades: return values and exceptions. These features essentially solve the error-handling problem outright, and provide the building blocks (structured data types) that you need to solve the JSON problem. But, since these semantics would utterly break compatibility with POSIX shell, they haven&rsquo;t been pushed in any mainstream Unix shell implementation I&rsquo;m aware of. <em>Outside</em> the mainstream, folks have been trying to re-integrate features like this into shell <a href=https://wryun.github.io/es-shell/paper.html>since at least as early as 1993</a>.</p><p>But for the rest of us, all this utility gets sacrificed on the altar of POSIX compatibility. Which&mldr; I mean, do we really even <em>need</em> to be POSIX compatible? Why do we care so much? Hell, I&rsquo;d argue a lot of shell code writers don&rsquo;t even realize when they are using <a href=https://mywiki.wooledge.org/Bashism>Bashisms</a> (or <em>Zshisms</em> for that matter). The times when we actually need to write very compatible shell code are quite limited, and you can use <a href=https://www.shellcheck.net/>ShellCheck</a> to check for many of the most common issues. Going further, you could look for a minimal <a href=https://unix.stackexchange.com/a/145524>POSIX-compatible shell</a> to develop against when you need this. That combined with, you know, <em>actual testing</em> will cover you for compatibility.</p><h2 id=alternative-shells>Alternative Shells<a hidden class=anchor aria-hidden=true href=#alternative-shells>#</a></h2><p>I don&rsquo;t want to pretend compatibility isn&rsquo;t important. There are clear times when various Unix-ecosystem constructs <a href=https://wiki.gentoo.org/wiki/Fish#Caveats>expect POSIX-compatibility</a>. But it is a <em>limited set of things</em> and is probably disjoint with 95% of your work unless you&rsquo;re a distro package maintainer. You are free to use non-compatible shell for most of your life, and drop into a simple Bourne-shell thingy in the rare event that you need it.</p><p>Let&rsquo;s elaborate: you have control on your personal machines. You almost certainly control what shell runs in your development environment. You might be able to influence what runs on your team&rsquo;s servers. These are all chances to try out new tools. But what tool to try?</p><p>This gets a bit tricky because, there&rsquo;s a ton of options, and no clear community consensus, as is always the case when veering away from mainstream technology; if there was consensus we&rsquo;d see a new branch in the mainstream, not an &ldquo;alternative shell&rdquo;. But there are a few generally good options.</p><p>I personally use <a href=https://fishshell.com/>Fish</a> as my daily driver, even though it only fixes one of my three main shell grips (the syntax one). But it comes with such a great out-of-the box interactive experience, that I can forgive it for not solving the others. I don&rsquo;t need perfect error handling at the command line as often, since there&rsquo;s a human in the loop. But I do love how it gets rid of POSIX shell eye-bleed in favor of a simple syntax and useful builtins. A lot of the <code>${var[@]##%}</code> gobbledygook gets replaced with the <a href=https://fishshell.com/docs/current/cmds/string.html><code>string</code></a> and <a href=https://fishshell.com/docs/current/cmds/string.html><code>path</code></a> commands. Completion works like a charm, with little gray suggestions quietly extending beyond your cursor, gingerly offering themselves to you as you type, without getting pushy and hyperactive. Quoting behavior becomes a non issue, and variables have the values you expect, with no subshells and clear variable scopes.</p><p>That said, I still think <code>fish</code> is a pretty lousy scripting language, because it doesn&rsquo;t solve the error/output problem. This is a big deal, and it&rsquo;s why I&rsquo;ve never bothered trying to fight with my team to install fish on servers or even use it in our repositories. But if you&rsquo;re used to POSIX-descendant shells, it&rsquo;s a great demonstration that it isn&rsquo;t that hard to ditch all that historical baggage. Fish easy to get used to, and with the compatibility layer <a href=https://github.com/edc/bass><code>bass</code></a> installed, you can consume bash scripts with ease, so you don&rsquo;t get locked out of the shell-script ecosystem. It will give you a taste of what a better experience is like, with sensible defaults out-of-the box, without having to install an <a href=https://ohmyz.sh/>enormous framework or trying to sell you cringe T-shirts</a>. Anecdotally, it&rsquo;s also much faster than most <code>bash</code> or <code>zsh</code>-based plugin things I&rsquo;ve tried, probably because most of the salient features are implemented in native code.</p><p>Windows users would be remiss if I didn&rsquo;t mention <a href=https://github.com/PowerShell/PowerShell>PowerShell</a>, which is definitely not POSIX compatible and was never intended to be. I stopped working with Windows before I ever really learned it, so I&rsquo;m not sure what the fuss is about, but it does seem to have structured data and is oriented around pipelines. And what do you know, it&rsquo;s available on MacOS and Linux too! But it requires the (very large) Common Language Runtime VM and God-knows-what-else .NET gunk to run. So I&rsquo;m going to pass on PowerShell for Unix. But if I ever end up in a project working with Windows again, I think it would be worth investing time to learn it instead of trying to hack it out with Unix shells on WSL.</p><p>In that vein, if you&rsquo;re interested in the structured data pipelines emphasis, <a href=https://github.com/nushell/nushell>Nushell</a> has you covered. Drawing on the design of PowerShell, Nushell aims to be cross-platform by default, and generally seems to be a bit tidier and more parsimonious than the shell that inspired it. It focuses on tabular, structured data, and DSLs for manipulating that. To this end, it reimplements a lot of typical Unix-style programs directly in the shell, to make them more aware of this data format. This does give me a bit of pause though. I&rsquo;ve become skeptical of tools that become so convinced of the power of a particular worldview that they start contorting everything around them to fit that model. In a shell, if this made interacting with regular programs feel second-class, then it starts to move away from that &ldquo;DSL for calling programs&rdquo; sweet spot, and more into a &ldquo;systems data processing language.&rdquo; But I haven&rsquo;t really tried it yet, so I can&rsquo;t say if this is a valid criticism or just armchair architecture critique. Overall, with some neat ideas and a lot of polish put on it, Nushell definitely looks worth trying.</p><p>Another candidate for a replacement shell is <a href=https://github.com/elves/elvish>Elvish</a>. In some ways it seems similar to Nushell, but with less emphasis on the table presentation layer and more emphasis on being like a functional dynamic programming language. It really aims to feel like a big boy language, except with sigils and barewords-as-strings. At first glance, I&rsquo;m getting &ldquo;readable Perl&rdquo; or &ldquo;restrained Ruby&rdquo; vibes, which I mean as compliments. Both of those languages arose out of the frustrations with handling more complex tasks in shell scripts. It also seems to avoid re-implementing common commands like Nushell, which makes me suspect it will feel a bit more natural interacting with tools you find in the wild. My only worry is that all this PL-focus—there&rsquo;s mentions of work on package managers and type systems and macros!—will detract from the simple, raw domain logic you want in shell scripts. Advanced features like this make it much easier to build a big goopy mess. A big ball of mud is still a big ball of mud even if it&rsquo;s really elegant mud.</p><p>The last alternative shell I&rsquo;ll discuss is the <a href=https://oils.pub/>Oils Project</a>, which aims to provide an &ldquo;upgrade path from Bash to a better language and runtime.&rdquo; It does this by providing a Bash-compatible mode <code>osh</code> and then allowing you to layer on options until you get to <code>ysh</code>, a target language that ticks all the boxes I have, without even sacrificing compatibility. Seriously. It has exception-based error handling, actual return values, structured data, native JSON capabilities, and a <em>Bash-compatible mode</em>. Granted, the way it achieves this is by essentially having two language modes embedded into one: command mode, which is more like classic shell, and expression mode, which is more like Python on JavaScript. This does make it a bit more complex, and one of my big criticisms of Oil has got to be the syntax, which I&rsquo;d suggest looks quite busy.</p><p>It&rsquo;s also sorely lacking in polish, and I&rsquo;m not sure it will ever be &ldquo;finished&rdquo; in any meaningful sense. As of today, there is no cute and easy installer; you have to build it from source to prove that you are worthy.<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> The interactive experience is somewhat humdrum. The docs are incomplete. For a project that has being going on for 8-9 years that seems suspect. There are still important design decisions being worked out in the open. But at the same time, it&rsquo;s almost refreshing seeing that someone is willing to be so deliberate when designing a language. And you can follow all of that design thinking in the Oils <a href=https://oils.pub/blog/>blog</a> which <a href=https://www.oilshell.org/blog/>goes back for years</a>. So it&rsquo;s worth reading up on the thought process that went into this, even if you don&rsquo;t end up using it.</p><p>For me, Oils is simultaneously the most promising and most frustrating option. It legitimately aims to provide a path for us to &ldquo;get off the Bell Labs timeline&rdquo;, but I don&rsquo;t know where this path leads. And I&rsquo;m not sure the Oils folks know either! That could be exciting, but I feel like I need more re-assurance that a project will start to stabilize before I start leaning on it for load-bearing elements of my work.</p><h2 id=final-thoughts>Final Thoughts<a hidden class=anchor aria-hidden=true href=#final-thoughts>#</a></h2><p>This may seem like a long, long post for such a lukewarm take—I am certainly neither the first nor the last person to claim the Bourne/POSIX shell sucks—but it&rsquo;s a damn travesty that we are stuck here. The utility and power of the shell was what drew me into computing. It&rsquo;s still one of the main selling points of Unix, sitting right at the core of the Unix philosophy: it is (generally) better to have many simple tools and a rich way to compose them than to have few complex tools that can&rsquo;t work together. This notion is held back by weaknesses in the composition language.</p><p>I&rsquo;d go so far as to argue that the creation of many modern overly-complex god-programs is in some way attributable to the weaknesses of shell. Do you like to hate on <code>systemd</code>? I sure do! Well, it replaced a bunch of shitty, hard-to-maintain shell scripts for the folks who do nuts-and-bolts Linux distro work. Who knows? Maybe better shell could have prevented it. Are you tired of editing YAML for a living? A lot of that YAML is replacing things that could be expressed in shell, except shell can&rsquo;t express structured data well so we have to embed shell inside of config files. Oops, I typed <code>${var}</code> when I meant <code>{{.var}}</code>. Or was it <code>${{var}}</code>? How silly of me to confuse one of the 5 templating languages I work with for another!</p><p>We are seriously still living in the past in so many ways because of this nonsense. And unlike some other ancient Unix jank like signals, we could mostly get rid of this! We generally get to pick the programs we write code in. There are some exceptions-login shells need to be able to process <code>/etc/profile</code>, and some tools like Vi or GDB expect <code>$SHELL</code> to reference a POSIX shell—but for the most part you can write shell scripting in whatever you want if you add a <code>#!/she/bang</code>, so what&rsquo;s stopping us?</p><p>Try one of these alternative shells. Seriously! Give it a go. If you&rsquo;re not a big shell user,then maybe having a shell language with decent semantics will open your eyes to a new way of working. If you use shell all the time, it might be hard to break from usual habits, but you may end up liking it! If none of the alternatives I listed are appealing to you, take a look at the Oils wiki&rsquo;s <a href=https://github.com/oils-for-unix/oils/wiki/Alternative-Shells>list of alternative shells</a> and find something you like.</p><p>To move on from the Bell Labs timeline, we need to gain a critical mass of developers that regularly and confidently use non-POSIX shells. One of the better arguments for sticking with these old-timey shells is that they are well-worn and battle-tested. They have their faults but we know where they are. The only way to counter that is to start testing an alternative in new battles! Do this locally and privately at first.</p><p>Don&rsquo;t start jamming it into shared load-bearing infrastructure at work without talking to your team. No one likes being surprised with shiny new tech they don&rsquo;t know without being consulted. This kinda thing leaves a bad taste in people&rsquo;s mouths. It is perfectly reasonable to be skeptical of new technology, and perfectly understandable to be resentful when it is shoved down your throats. I don&rsquo;t think any developers I know <em>love</em> POSIX shell, but many reasonable and intelligent folks think it&rsquo;s the best choice given all the trade-offs. So I&rsquo;m not going to fight to install a neoshell on our servers until I fully understand the implications of what that means.</p><p>That said, if you find yourself liking one of these, show it off to your team! Feature it during demo day, either live, or by scripting up some actions that you want to show off. Use it to solve problems you found difficult. Talk about it. Write about it. Emit microblog status updates about it. Show the world that there are alternatives. As I said before, I don&rsquo;t think people love POSIX shell, I just think they are just resigned to the sludge, convinced that it is the <em>least bad</em> option for the task. Can we show them some <em>good</em> options?</p><p>We don&rsquo;t all have to program in C anymore. Maybe one day we won&rsquo;t all have to script in <code>sh</code>.</p><hr><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>I&rsquo;m aware that shell is Turing complete and thus technically capable of writing any program. Thanks for reminding me, <em>nerd</em>. But I&rsquo;m talking more about what shell&rsquo;s design encourages and makes easy than what is technically possible.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>I could probably levy this criticism at almost every language. There have been more features pioneered in Lisp than you can probably imagine, and there&rsquo;s still some <em>great</em> ones that have yet to go mainstream. Did you know you can make exception handling code that prompts the user to <a href=https://novaspec.org/cl/f_restart-case>choose options to fix the error condition</a>?&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>It&rsquo;s not complicated and it builds fast, but this will be a hurdle to adoption for a lot of folks who&rsquo;d rather just copy <code>curl -sSf https://oils.pub/get-oils | sh</code> into a terminal and press enter.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://www.jriddy.com/>Josh Reed</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>